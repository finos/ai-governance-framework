@startuml RAG_System
!include https://raw.githubusercontent.com/plantuml-stdlib/C4-PlantUML/master/C4_Container.puml

' Global layout options for better arrow symmetry
!define DIRECTION top to bottom direction
skinparam linetype ortho
skinparam nodesep 60
skinparam ranksep 100
skinparam minlen 2
skinparam LabelFontSize 10
skinparam ArrowFontSize 9

title RAG System Architecture

Person(user, "User", "Performs queries against RAG system")

Enterprise_Boundary(org, "Organization") {
    Container(tests, "Tests", "Test Suite", "System validation")
    
    System_Boundary(data_proc, "A) RAG Knowledge base preparation\nData Processing Environment\n(Internal OnPrem/Cloud)") {
        ContainerDb(pks, "Private Knowledge Data Source", "Database", "Raw organizational data")
        Container(dpf, "Data Processor and Filtering", "Service", "Processes and filters data")
        ContainerDb(rks, "Refined Knowledge Data Source", "Database", "Cleaned and processed data")
        Container(vdl, "Vector Data Loader", "Service", "Converts data to embeddings")
        ContainerDb(vdb, "Vector Database", "Vector Store", "Stores embeddings for retrieval")
    }
    
    System_Boundary(instrumentation, "B) RAG Inference for users\nInstrumentation Environment\n(Internal OnPrem/Cloud)") {
        Container(user_query, "User Query", "Interface", "Query input")
        Container(query_proc, "Query Processing", "Service", "Orchestrates RAG pipeline")
    }
    
    System_Boundary(inference, "Inference Environment (SaaS)") {
        Container(emb_endpoint, "Embeddings Endpoint", "API", "Generates embeddings")
        ContainerDb(emb_model, "Embeddings Model", "ML Model Store", "Text embedding model weights/data")
        Container(inf_endpoint, "Inference Endpoint", "API", "Handles inference requests")
        ContainerDb(llm_model, "LLM Model", "ML Model Store", "Large language model weights/data")
    }
    
    ' Layout positioning hints
    data_proc -[hidden]down-> instrumentation
    instrumentation -[hidden]right-> inference
    data_proc -[hidden]right-> inference
}

' Data flow relationships
Rel(pks, dpf, "Raw data")
Rel(dpf, rks, "Processed data")
Rel(rks, vdl, "Refined data")
Rel(vdl, vdb, "Vector embeddings")

' Cross-environment relationships - preparation
Rel(vdl, emb_endpoint, "Embedding requests", "HTTPS")
Rel(emb_model, emb_endpoint, "Vector embeddings")
Rel(emb_endpoint, emb_model, "Text to embed")

' Inference environment internal flow
Rel(inf_endpoint, llm_model, "Generation requests")
Rel(llm_model, inf_endpoint, "Generated responses")

' User flow
Rel(user, user_query, "Request")
Rel(tests, user_query, "Validated queries")
Rel(user_query, tests, "Test responses")
Rel(user_query, query_proc, "User input")

' Cross-environment inference connections
Rel(query_proc, vdb, "Vector search", "Retrieval")
Rel(query_proc, emb_endpoint, "Query embedding", "HTTPS")
Rel(query_proc, inf_endpoint, "Inference request", "HTTPS")
Rel(user_query, user, "Response")

SHOW_LEGEND()
@enduml