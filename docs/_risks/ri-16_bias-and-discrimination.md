---
sequence: 16
title: Bias and Discrimination
layout: risk
doc-status: Pre-Draft
type: OP
---

  - AI trained on historical/internet data may embed biases.  
  - Can lead to discriminatory outcomes.  
  - e.g Risk of biased credit decisions, Potential for unfair pricing, Exclusion of certain groups.  

Data trained on a single source or similar sources can lead to bias. 
If you train you're AI system in old data (pre GFC fro example) will be biased
Geography / jurisdiction prespective 
How do you define "good data" vs "bad data" 
Does the vendor have a policy for making sure the data is not bias 
If you are a Uuropean bank you need to be DORA compliant and this means effectively the vendor and dataset need to be Nth party compliant for 3rd TP RM requirments 
Continuos monitoirng, provission against data poisioning, conform with the EU AI Act 

From a credit lending perspective, PII (name, zipcode etc.) which might lead to bias (minority classification)
