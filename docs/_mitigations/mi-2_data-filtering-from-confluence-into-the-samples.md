---
sequence: 2
title: Data Filtering From External Knowledge Bases
layout: mitigation
doc-status: Draft
type: PREV
external_risks:
  - ISO-42001_2023_A-7-2 # Data for development and enhancement of AI systems
  - ISO-42001_2023_A-7-3 # Acquisition of data
  - ISO-42001_2023_A-7-4 # Quality of data for AI systems
  - ISO-42001_2023_A-7-6 # Data preparation

mitigates:
  - ri-1  # Information Leaked To Hosted Model
---

#### Core Control Measures
To reduce the risk of sensitive data exposure or corruption when AI systems learn from or retrieve information from internal knowledge bases, the following measures should be implemented:

##### 1. Rigorous Data Cleansing and Anonymization:
  * **Process**: Before any information from internal knowledge sources is used by an AI system (e.g., for training, or as a basis for generating responses), it must undergo a thorough review and cleansing process.
  * **Objective**: This process involves identifying and then removing or obscuring (anonymizing) sensitive details. The aim is to ensure that the data fed into the AI system is free from information that could pose a security or privacy risk if inadvertently exposed.
  * **Examples of Data to Target**:
    - Personally Identifiable Information (PII) like names, contact details, financial account numbers, or employee IDs.
    - Proprietary business information, such as trade secrets, intellectual property, unreleased financial results, or strategic plans.
    - Sensitive internal operational data or security configurations not intended for broader access via an AI system.
  * **Methods**: Techniques can include masking specific data fields, redacting sections of documents, or generalizing information to reduce its specificity.

##### 2. Segregation for Highly Sensitive Data (If Applicable):
  * **Concept**: For datasets or knowledge sources containing exceptionally sensitive information that cannot be adequately protected through standard cleansing or anonymization techniques, consider using isolated AI systems or environments.
  * **Implementation**: This could involve creating separate, highly secured AI models and their associated data stores (e.g., vector databases used in Retrieval Augmented Generation systems) with much stricter access controls.
  * **Benefit**: This ensures that only explicitly authorized personnel or tightly controlled AI processes can interact with this highly sensitive data, minimizing the risk of broader exposure.
  
##### 3. Filtering AI System Outputs:
* **Rationale**: As an additional layer of defense, responses and information generated by the AI system should also be monitored and filtered before being presented to users or other systems.
* **Function**: This acts as a crucial safety net to detect and remove any sensitive data that might have inadvertently bypassed the initial input cleansing stages or was unexpectedly reconstructed or inferred by the AI model.
* **Scope**: These output checks should be guided by the same principles and rules used for sanitizing the input data.

#### Importance and Benefits
Implementing robust data filtering from external knowledge bases is a critical preventative measure. By meticulously controlling the information that enters the AI system's operational environment (including its training data and any knowledge it accesses for generating responses), organizations can significantly reduce the attack surface and the risk of unauthorized data access, leakage, or malicious alteration.

This control is particularly important given the evolving nature of AI technologies and the sophisticated ways they interact with and process large volumes of information. A proactive approach to data sanitization helps maintain confidentiality, integrity, and compliance.
